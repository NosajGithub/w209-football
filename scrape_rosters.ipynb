{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import lxml\n",
    "import re\n",
    "\n",
    "def getInjuries(team, year):\n",
    "    \"\"\"\n",
    "    Scrapes one page of injury information\n",
    "    \"\"\"\n",
    "\n",
    "    # Scrape roster information\n",
    "    content = urllib.urlopen(\"http://www.pro-football-reference.com/teams/\" + team + \"/\" + year + \"_roster.htm\")\n",
    "    s = content.read()\n",
    "    soup = BeautifulSoup(s, 'lxml')\n",
    "\n",
    "    table = soup.find_all('table')[1]\n",
    "    roster = pd.read_html(str(table))[0]\n",
    "    \n",
    "    new_columns = roster.columns.values\n",
    "    new_columns[1] = 'name'\n",
    "    roster.columns = new_columns\n",
    "    \n",
    "    roster['name'] = [re.sub('[*]|[+]', '', name) for name in roster['name']]\n",
    "    roster[roster['name'] != \"Team Total\"]\n",
    "    roster['team'] = team\n",
    "    roster['year'] = year\n",
    "    \n",
    "    roster = roster.drop(roster.index[-1]) # Get rid of \"team total\"\n",
    "    \n",
    "    roster = roster.loc[:,['team','year','name','G','Yrs','Age']]\n",
    "    \n",
    "    return roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crd 2009\n",
      "crd 2010\n",
      "crd 2011\n",
      "crd 2012\n",
      "crd 2013\n",
      "crd 2014\n",
      "atl 2009\n",
      "atl 2010\n",
      "atl 2011\n",
      "atl 2012\n",
      "atl 2013\n",
      "atl 2014\n",
      "rav 2009\n",
      "rav 2010\n",
      "rav 2011\n",
      "rav 2012\n",
      "rav 2013\n",
      "rav 2014\n",
      "buf 2009\n",
      "buf 2010\n",
      "buf 2011\n",
      "buf 2012\n",
      "buf 2013\n",
      "buf 2014\n",
      "car 2009\n",
      "car 2010\n",
      "car 2011\n",
      "car 2012\n",
      "car 2013\n",
      "car 2014\n",
      "chi 2009\n",
      "chi 2010\n",
      "chi 2011\n",
      "chi 2012\n",
      "chi 2013\n",
      "chi 2014\n",
      "cin 2009\n",
      "cin 2010\n",
      "cin 2011\n",
      "cin 2012\n",
      "cin 2013\n",
      "cin 2014\n",
      "cle 2009\n",
      "cle 2010\n",
      "cle 2011\n",
      "cle 2012\n",
      "cle 2013\n",
      "cle 2014\n",
      "dal 2009\n",
      "dal 2010\n",
      "dal 2011\n",
      "dal 2012\n",
      "dal 2013\n",
      "dal 2014\n",
      "den 2009\n",
      "den 2010\n",
      "den 2011\n",
      "den 2012\n",
      "den 2013\n",
      "den 2014\n",
      "det 2009\n",
      "det 2010\n",
      "det 2011\n",
      "det 2012\n",
      "det 2013\n",
      "det 2014\n",
      "gnb 2009\n",
      "gnb 2010\n",
      "gnb 2011\n",
      "gnb 2012\n",
      "gnb 2013\n",
      "gnb 2014\n",
      "htx 2009\n",
      "htx 2010\n",
      "htx 2011\n",
      "htx 2012\n",
      "htx 2013\n",
      "htx 2014\n",
      "clt 2009\n",
      "clt 2010\n",
      "clt 2011\n",
      "clt 2012\n",
      "clt 2013\n",
      "clt 2014\n",
      "jax 2009\n",
      "jax 2010\n",
      "jax 2011\n",
      "jax 2012\n",
      "jax 2013\n",
      "jax 2014\n",
      "kan 2009\n",
      "kan 2010\n",
      "kan 2011\n",
      "kan 2012\n",
      "kan 2013\n",
      "kan 2014\n",
      "mia 2009\n",
      "mia 2010\n",
      "mia 2011\n",
      "mia 2012\n",
      "mia 2013\n",
      "mia 2014\n",
      "min 2009\n",
      "min 2010\n",
      "min 2011\n",
      "min 2012\n",
      "min 2013\n",
      "min 2014\n",
      "nwe 2009\n",
      "nwe 2010\n",
      "nwe 2011\n",
      "nwe 2012\n",
      "nwe 2013\n",
      "nwe 2014\n",
      "nor 2009\n",
      "nor 2010\n",
      "nor 2011\n",
      "nor 2012\n",
      "nor 2013\n",
      "nor 2014\n",
      "nyg 2009\n",
      "nyg 2010\n",
      "nyg 2011\n",
      "nyg 2012\n",
      "nyg 2013\n",
      "nyg 2014\n",
      "nyj 2009\n",
      "nyj 2010\n",
      "nyj 2011\n",
      "nyj 2012\n",
      "nyj 2013\n",
      "nyj 2014\n",
      "rai 2009\n",
      "rai 2010\n",
      "rai 2011\n",
      "rai 2012\n",
      "rai 2013\n",
      "rai 2014\n",
      "phi 2009\n",
      "phi 2010\n",
      "phi 2011\n",
      "phi 2012\n",
      "phi 2013\n",
      "phi 2014\n",
      "pit 2009\n",
      "pit 2010\n",
      "pit 2011\n",
      "pit 2012\n",
      "pit 2013\n",
      "pit 2014\n",
      "sdg 2009\n",
      "sdg 2010\n",
      "sdg 2011\n",
      "sdg 2012\n",
      "sdg 2013\n",
      "sdg 2014\n",
      "sfo 2009\n",
      "sfo 2010\n",
      "sfo 2011\n",
      "sfo 2012\n",
      "sfo 2013\n",
      "sfo 2014\n",
      "sea 2009\n",
      "sea 2010\n",
      "sea 2011\n",
      "sea 2012\n",
      "sea 2013\n",
      "sea 2014\n",
      "ram 2009\n",
      "ram 2010\n",
      "ram 2011\n",
      "ram 2012\n",
      "ram 2013\n",
      "ram 2014\n",
      "tam 2009\n",
      "tam 2010\n",
      "tam 2011\n",
      "tam 2012\n",
      "tam 2013\n",
      "tam 2014\n",
      "oti 2009\n",
      "oti 2010\n",
      "oti 2011\n",
      "oti 2012\n",
      "oti 2013\n",
      "oti 2014\n",
      "was 2009\n",
      "was 2010\n",
      "was 2011\n",
      "was 2012\n",
      "was 2013\n",
      "was 2014\n"
     ]
    }
   ],
   "source": [
    "## Get all pages to scrape\n",
    "teams = [\"crd\", \"atl\", \"rav\", \"buf\",\"car\",\"chi\",\"cin\",\"cle\",\"dal\",\"den\",\"det\",\"gnb\",\"htx\",\"clt\",\"jax\",\"kan\",\"mia\",\"min\",\n",
    "           \"nwe\",\"nor\",\"nyg\",\"nyj\",\"rai\",\"phi\",\"pit\",\"sdg\",\"sfo\",\"sea\",\"ram\",\"tam\",\"oti\",\"was\"]\n",
    "years = ['2009','2010','2011','2012','2013','2014']\n",
    "team_years = [(x,y) for x in teams for y in years]\n",
    "\n",
    "## Scrape each of the pages\n",
    "output = pd.DataFrame()\n",
    "for a,b in team_years:\n",
    "    print a, b\n",
    "    sleep(randint(1,3))\n",
    "    sleep(randint(1,3))    \n",
    "    output = output.append(getInjuries(a,b))\n",
    "\n",
    "output['year'] = output['year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>G</th>\n",
       "      <th>Yrs</th>\n",
       "      <th>Age</th>\n",
       "      <th>position</th>\n",
       "      <th>caps_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crd</td>\n",
       "      <td>2009</td>\n",
       "      <td>Hamza Abdullah</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>CB</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crd</td>\n",
       "      <td>2009</td>\n",
       "      <td>Michael Adams</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>S</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crd</td>\n",
       "      <td>2009</td>\n",
       "      <td>Jason Banks</td>\n",
       "      <td>1</td>\n",
       "      <td>Rook</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crd</td>\n",
       "      <td>2009</td>\n",
       "      <td>Anthony Becht</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>TE</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crd</td>\n",
       "      <td>2009</td>\n",
       "      <td>Monty Beisel</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>LB</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  team  year            name   G   Yrs  Age position caps_team\n",
       "0  crd  2009  Hamza Abdullah   1     4   26       CB       ARI\n",
       "1  crd  2009   Michael Adams  16     2   24        S       ARI\n",
       "2  crd  2009     Jason Banks   1  Rook   24      NaN       ARI\n",
       "3  crd  2009   Anthony Becht  16     9   32       TE       ARI\n",
       "4  crd  2009    Monty Beisel   6     8   31       LB       ARI"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in POS\n",
    "brad_pos = pd.read_csv(\"brad_positions.csv\") #Removed Greg Jones in 2012 from JAX (ILB and FB)\n",
    "\n",
    "team_dict ={\n",
    "    'ATL': 'atl','BUF': 'buf','CAR': 'car','CHI': 'chi',\n",
    "    'CIN': 'cin','CLE': 'cle','IND': 'clt','ARI': 'crd',\n",
    "    'DAL': 'dal','DEN': 'den','DET': 'det','GB': 'gnb',\n",
    "    'HOU': 'htx','JAC': 'jax','KC': 'kan','MIA': 'mia',\n",
    "    'MIN': 'min','NO': 'nor','NE': 'nwe','NYG': 'nyg',\n",
    "    'NYJ': 'nyj','TEN': 'oti','PHI': 'phi','PIT': 'pit',\n",
    "    'OAK': 'rai','STL': 'ram','BAL': 'rav','SD': 'sdg',\n",
    "    'SEA': 'sea','SF': 'sfo','TB': 'tam','WAS': 'was'\n",
    "}\n",
    "\n",
    "brad_pos['team'] = brad_pos.apply(lambda row: team_dict[row['team']], axis=1)\n",
    "\n",
    "df2 = pd.merge(output, brad_pos, how='left', on=['name','year','team'])\n",
    "\n",
    "bigteam_dict = dict(zip(team_dict.values(),team_dict.keys()))\n",
    "df2['caps_team'] = df2.apply(lambda row: bigteam_dict[row['team']], axis=1)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip players who didn't play at least 3 games\n",
    "stripped = pd.read_csv(\"stripped.csv\") #Removed Greg Jones in 2012 from JAX (ILB and FB)\n",
    "\n",
    "df3 = pd.merge(df2, stripped, how='left', on=['name','year','team'])\n",
    "\n",
    "df4 = df3[pd.isnull(df3['count'])]\n",
    "\n",
    "# Limit to relevant columns\n",
    "df4.loc[:,'team'] = df4.loc[:,'caps_team']\n",
    "df4 = df4.drop(['count','caps_team'], 1)\n",
    "\n",
    "# Output\n",
    "df4.to_csv(\"roster_info.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip players in the injury list but not on the roster\n",
    "roster_nyt = df3[pd.isnull(df3['count'])]\n",
    "roster_nyt = roster_nyt.loc[:,['name','year','team','G']]\n",
    "\n",
    "injuries = pd.read_csv(\"injuries_unique_jkg_clean.csv\") #Removed Greg Jones in 2012 from JAX (ILB and FB)\n",
    "injuries = injuries.drop('Unnamed: 0',1)\n",
    "\n",
    "injuries_pruned = pd.merge(injuries, roster_nyt, how='inner', on=['name','year','team'])\n",
    "\n",
    "injuries_pruned.to_csv(\"injuries_unique_jkg_clean_pruned.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
